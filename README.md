# 🧠 自然语言处理四种方法实践指南

---

## 🌟 概述
1. **✂ 文本预处理**  
   ```使用 jieba 中文分词工具，将评论文本标准化并分词，为后续向量化处理打基础。```
   
2. **🔢 特征提取**  
   ```统一采用 CountVectorizer 提取文本词频特征，构建训练与预测数据矩阵。```
   
3. **🧪 模型训练与验证**  
   ```使用四种主流机器学习方法：朴素贝叶斯、决策树、K 最近邻、随机森林，比较各自的分类效果。```
   
4. **📊 模型评估指标**  
   ```输出 Accuracy、Precision、Recall、F1 分数，全面衡量分类性能。```

---

## 🧰 使用模型一览
### 📗 模型一：Naive Bayes（朴素贝叶斯）
- **技术亮点**  
  ```利用 MultinomialNB 适应文本分类的词频特性```  
  ```精简训练流程，适合轻量快速建模场景```
  
- **核心流程**  
  ```jieba 分词 → CountVectorizer 向量化 → MultinomialNB 模型训练```  
  ```预测数据输出结果并保存```

---

### 🌲 模型二：Decision Tree（决策树）
- **技术亮点**  
  ```构造规则树，逻辑可解释性强```  
  ```可处理非线性分类边界```
  
- **特别处理**  
  ```手动定义分词函数 tokenize，提高语义切分精准度```  
  ```明确转换字段为字符串避免数据类型问题```

---

### 🧭 模型三：K-Nearest Neighbors（K 最近邻）
- **技术亮点**  
  ```基于“邻近相似”原则进行分类```  
  ```无需训练过程，适合小样本、直观理解场景```
  
- **实践注意**  
  ```文本向量化后标准化尤为重要，KNN 对距离敏感```  
  ```K 值默认未展示选择策略，后续可调参优化```

---

### 🌳 模型四：Random Forest（随机森林）
- **技术亮点**  
  ```多棵决策树集成，增强泛化能力```  
  ```适用于高维稀疏特征空间的分类问题```
  
- **表现亮点**  
  ```准确率通常高于单棵决策树```  
  ```抗过拟合能力强，鲁棒性高```

---

## 🔁 模型对比分析
- **统一评估指标**  
  ```Accuracy | Precision | Recall | F1-score```
  
- **分析亮点**  
  ```各模型对训练集的拟合表现对比直观```  
  ```可用作模型选择的基准实验框架```

---

## 📂 数据说明
- ```Training_set.xlsx：包含评论文本及情感标签```
- ```Predict.xlsx：需分类的无标签评论集```

---

## 🧪 技术栈汇总
| 类别       | 工具                                      |
|------------|------------------------------------------|
| 文本处理   | jieba                                    |
| 特征工程   | CountVectorizer                          |
| 模型库     | sklearn.naive_bayes, sklearn.tree,<br>sklearn.neighbors, sklearn.ensemble |
| 评估指标   | accuracy_score, precision_score,<br>recall_score, f1_score |

---

## 🔗 推荐资源
- 📘 [Scikit-learn 文档](https://scikit-learn.org/stable/documentation.html)
- 🧠 [jieba 分词 GitHub](https://github.com/fxsjy/jieba)

---

## 📌 小贴士
```若处理自定义数据，请统一编码与列名格式```  
```可尝试加入 TF-IDF 特征、词向量模型优化分类效果```
